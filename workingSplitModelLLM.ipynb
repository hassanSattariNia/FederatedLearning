{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq6C_Pv9atVw",
        "outputId": "261a9cc8-4c27-4724-ca08-0a76aabd8be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall torch -y\n",
        "!pip install torch==2.4.1+cu121 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnL5-lKWowc9",
        "outputId": "a0fb058c-c417-436a-8274-fd59fb45afbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.4.1+cu121 in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1+cu121) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1+cu121) (12.6.77)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1+cu121) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1+cu121) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score  # Add this line"
      ],
      "metadata": {
        "id": "SXtCMCet8C5P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertModel, AlbertTokenizer\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification\n"
      ],
      "metadata": {
        "id": "8U_u2Ikna1td"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GLUE MRPC dataset\n",
        "dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"albert-base-v2\"\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "model = AlbertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUQ0pD50bgDS",
        "outputId": "cf1c90af-4be1-4bf5-aefc-f05e7e1f97a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "# return trainable parameter of model\n",
        "def count_parameters(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "def split_model_comprehensive(model, num_clients=4):\n",
        "    # Comprehensive list of all modules in the ALBERT-v2 model\n",
        "    modules = [\n",
        "        ('embeddings.word_embeddings', model.embeddings.word_embeddings),\n",
        "        ('embeddings.position_embeddings', model.embeddings.position_embeddings),\n",
        "        ('embeddings.token_type_embeddings', model.embeddings.token_type_embeddings),\n",
        "        ('embeddings.LayerNorm', model.embeddings.LayerNorm),\n",
        "        ('encoder.embedding_hidden_mapping_in', model.encoder.embedding_hidden_mapping_in),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].full_layer_layer_norm),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.query',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.query),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.key',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.key),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.value',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.value),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.dense',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.dense),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.LayerNorm),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.dropout',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.attention_dropout),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.attention.output_dropout',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].attention.output_dropout),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.ffn',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].ffn),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.ffn_output',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].ffn_output),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.activation',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].activation),\n",
        "        ('encoder.albert_layer_groups.0.albert_layers.0.dropout',\n",
        "         model.encoder.albert_layer_groups[0].albert_layers[0].dropout),\n",
        "        ('pooler', model.pooler),\n",
        "        ('pooler_activation', model.pooler_activation)\n",
        "    ]\n",
        "\n",
        "    # Calculate total parameters\n",
        "    total_params = sum(count_parameters(module) for _, module in modules)\n",
        "    print(f'total params of list modules is ${total_params}')\n",
        "    target_params_per_client = total_params // num_clients\n",
        "    print(f'expected params of one client ${target_params_per_client}')\n",
        "\n",
        "    client_modules = [[] for _ in range(num_clients)]\n",
        "    current_client = 0\n",
        "    current_client_params = 0\n",
        "\n",
        "    for name, module in modules:\n",
        "        client_modules[current_client].append((name, module))\n",
        "        module_params = count_parameters(module)\n",
        "        current_client_params += module_params\n",
        "        print(f\"name :${name} , current client:${current_client} , module parameter :${module_params} , currentParameterClient:${current_client_params},t:{current_client_params + module_params} \")\n",
        "        # Check if adding this module exceeds the target per client and we haven't reached the last client\n",
        "        if current_client_params > target_params_per_client  and current_client < num_clients - 1:\n",
        "            current_client += 1\n",
        "            current_client_params = 0\n",
        "\n",
        "        # Assign the module to the current client\n",
        "\n",
        "    return client_modules\n",
        "\n",
        "# Load ALBERT model\n",
        "model = AlbertModel.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "# Split the model between 4 clients\n",
        "client_models = split_model_comprehensive(model, num_clients=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dk639lu-GJ_",
        "outputId": "e45ecff9-b370-4044-e440-3784e40087e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total params of list modules is $11683584\n",
            "expected params of one client $2920896\n",
            "name :$embeddings.word_embeddings , current client:$0 , module parameter :$3840000 , currentParameterClient:$3840000,t:7680000 \n",
            "name :$embeddings.position_embeddings , current client:$1 , module parameter :$65536 , currentParameterClient:$65536,t:131072 \n",
            "name :$embeddings.token_type_embeddings , current client:$1 , module parameter :$256 , currentParameterClient:$65792,t:66048 \n",
            "name :$embeddings.LayerNorm , current client:$1 , module parameter :$256 , currentParameterClient:$66048,t:66304 \n",
            "name :$encoder.embedding_hidden_mapping_in , current client:$1 , module parameter :$99072 , currentParameterClient:$165120,t:264192 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm , current client:$1 , module parameter :$1536 , currentParameterClient:$166656,t:168192 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.query , current client:$1 , module parameter :$590592 , currentParameterClient:$757248,t:1347840 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.key , current client:$1 , module parameter :$590592 , currentParameterClient:$1347840,t:1938432 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.value , current client:$1 , module parameter :$590592 , currentParameterClient:$1938432,t:2529024 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.dense , current client:$1 , module parameter :$590592 , currentParameterClient:$2529024,t:3119616 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm , current client:$1 , module parameter :$1536 , currentParameterClient:$2530560,t:2532096 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.dropout , current client:$1 , module parameter :$0 , currentParameterClient:$2530560,t:2530560 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.attention.output_dropout , current client:$1 , module parameter :$0 , currentParameterClient:$2530560,t:2530560 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.ffn , current client:$1 , module parameter :$2362368 , currentParameterClient:$4892928,t:7255296 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.ffn_output , current client:$2 , module parameter :$2360064 , currentParameterClient:$2360064,t:4720128 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.activation , current client:$2 , module parameter :$0 , currentParameterClient:$2360064,t:2360064 \n",
            "name :$encoder.albert_layer_groups.0.albert_layers.0.dropout , current client:$2 , module parameter :$0 , currentParameterClient:$2360064,t:2360064 \n",
            "name :$pooler , current client:$2 , module parameter :$590592 , currentParameterClient:$2950656,t:3541248 \n",
            "name :$pooler_activation , current client:$3 , module parameter :$0 , currentParameterClient:$0,t:0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_models[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIDHzeuDMIQt",
        "outputId": "e4fea3c8-83c7-40e3-803f-d6e5bbb3e2c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('embeddings.word_embeddings', Embedding(30000, 128, padding_idx=0))]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client_models[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BByDH5Ez1dqz",
        "outputId": "efecc994-e898-42be-a677-bfb78e325914"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('embeddings.position_embeddings', Embedding(512, 128)),\n",
              " ('embeddings.token_type_embeddings', Embedding(2, 128)),\n",
              " ('embeddings.LayerNorm',\n",
              "  LayerNorm((128,), eps=1e-12, elementwise_affine=True)),\n",
              " ('encoder.embedding_hidden_mapping_in',\n",
              "  Linear(in_features=128, out_features=768, bias=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm',\n",
              "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.query',\n",
              "  Linear(in_features=768, out_features=768, bias=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.key',\n",
              "  Linear(in_features=768, out_features=768, bias=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.value',\n",
              "  Linear(in_features=768, out_features=768, bias=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.dense',\n",
              "  Linear(in_features=768, out_features=768, bias=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm',\n",
              "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.dropout',\n",
              "  Dropout(p=0, inplace=False)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.attention.output_dropout',\n",
              "  Dropout(p=0, inplace=False)),\n",
              " ('encoder.albert_layer_groups.0.albert_layers.0.ffn',\n",
              "  Linear(in_features=768, out_features=3072, bias=True))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display splitting information\n",
        "for i, parts in enumerate(client_models):\n",
        "    print(f\"Client {i+1}:\")\n",
        "    client_total_params = 0\n",
        "    for name, module in parts:\n",
        "        num_params = count_parameters(module)\n",
        "        client_total_params += num_params\n",
        "        print(f\"  - {name}: {num_params:,} parameters\")\n",
        "    print(f\"  Total client parameters: {client_total_params:,}\")\n",
        "    print()\n",
        "\n",
        "# Calculate total parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total model parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "ZV59D4211UBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fde9ae56-6294-42a0-876e-c44facf37194"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 1:\n",
            "  - embeddings.word_embeddings: 3,840,000 parameters\n",
            "  Total client parameters: 3,840,000\n",
            "\n",
            "Client 2:\n",
            "  - embeddings.position_embeddings: 65,536 parameters\n",
            "  - embeddings.token_type_embeddings: 256 parameters\n",
            "  - embeddings.LayerNorm: 256 parameters\n",
            "  - encoder.embedding_hidden_mapping_in: 99,072 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm: 1,536 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.query: 590,592 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.key: 590,592 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.value: 590,592 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.dense: 590,592 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm: 1,536 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.dropout: 0 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.attention.output_dropout: 0 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.ffn: 2,362,368 parameters\n",
            "  Total client parameters: 4,892,928\n",
            "\n",
            "Client 3:\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.ffn_output: 2,360,064 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.activation: 0 parameters\n",
            "  - encoder.albert_layer_groups.0.albert_layers.0.dropout: 0 parameters\n",
            "  - pooler: 590,592 parameters\n",
            "  Total client parameters: 2,950,656\n",
            "\n",
            "Client 4:\n",
            "  - pooler_activation: 0 parameters\n",
            "  Total client parameters: 0\n",
            "\n",
            "Total model parameters: 11,683,584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GLUE MRPC dataset\n",
        "dataset = load_dataset(\"glue\", \"mrpc\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "model_name = \"albert-base-v2\"\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "model = AlbertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Tokenize the dataset with padding and truncation\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True, padding='max_length', max_length=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm8ftK61Mxkl",
        "outputId": "59a40b11-0f95-4427-a2c9-1ca93f77dfad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][0])\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAx8dT2udzjg",
        "outputId": "25361dd4-e927-4e93-960c-93380bbcf627"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYIcV7X0egs_",
        "outputId": "83b41fe8-174d-4596-8ffe-21520559dfab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0, 'input_ids': [2, 589, 661, 2553, 4125, 33, 655, 13, 15, 1368, 24, 227, 13, 7, 14, 6165, 13, 7, 13, 15, 16, 10155, 1460, 2153, 1203, 33, 1445, 13, 9, 3, 7378, 20, 61, 28, 104, 13, 7, 14, 6165, 13, 7, 13, 15, 589, 661, 2553, 4125, 33, 655, 16, 10155, 1460, 2153, 1203, 33, 1445, 13, 9, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xjwgBLwtg2T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(['sentence1', 'sentence2'])\n",
        "\n",
        "# Create DataLoader with batch size of 16\n",
        "train_dataset = tokenized_datasets['train']\n",
        "eval_dataset = tokenized_datasets['validation']\n",
        "\n",
        "# Custom collate function to ensure correct batching\n",
        "# convert individual data to batch of data\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.tensor([item['input_ids'] for item in batch])\n",
        "    attention_mask = torch.tensor([item['attention_mask'] for item in batch])\n",
        "    token_type_ids = torch.tensor([item['token_type_ids'] for item in batch])\n",
        "    labels = torch.tensor([item['label'] for item in batch])\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_mask,\n",
        "        'token_type_ids': token_type_ids,\n",
        "        'labels': labels\n",
        "    }"
      ],
      "metadata": {
        "id": "vbv3NtGttBK6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration (for multiple devices)\n",
        "device1 = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device2 = torch.device(\"cuda:1\") if torch.cuda.device_count() > 1 else device1\n",
        "device3 = torch.device(\"cuda:2\") if torch.cuda.device_count() > 2 else device1\n",
        "\n",
        "print(device1 , device2 , device3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FOXAL0Vtkuy",
        "outputId": "c783a371-82ab-4fd2-8062-467b61c03906"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 cuda:0 cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف validation_dataloader\n",
        "validation_dataloader = DataLoader(eval_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "jgaDSSYZMg7p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process data through client 1 (embeddings)\n",
        "def forward_client_1(batch):\n",
        "    input_ids = batch['input_ids'].to(device1)\n",
        "    attention_mask = batch['attention_mask'].to(device1)\n",
        "    token_type_ids = batch['token_type_ids'].to(device1)\n",
        "\n",
        "    # Get the embedding output\n",
        "    embedding_output = model.albert.embeddings(\n",
        "        input_ids=input_ids,\n",
        "        token_type_ids=token_type_ids\n",
        "    )\n",
        "\n",
        "    # print(f\"Client 1 - Output Shape: {embedding_output.shape}, Device: {embedding_output.device}\")\n",
        "    return embedding_output\n",
        "\n",
        "# Function to process data through client 2 (encoder)\n",
        "def forward_client_2(embedding_output, attention_mask):\n",
        "    # Move embedding_output to device2\n",
        "    embedding_output = embedding_output.to(device2)\n",
        "    attention_mask = attention_mask.to(device2)\n",
        "\n",
        "    # Reshape attention_mask to (batch_size, 1, 1, sequence_length)\n",
        "    attention_mask = attention_mask[:, None, None, :]\n",
        "\n",
        "    # Continue processing from the encoder layers of client 2\n",
        "    encoder_output = model.albert.encoder(\n",
        "        embedding_output,\n",
        "        attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    # print(f\"Client 2 - Output Shape: {encoder_output.last_hidden_state.shape}, Device: {encoder_output.last_hidden_state.device}\")\n",
        "    return encoder_output\n",
        "\n",
        "# Function to process data through client 3 (classification head)\n",
        "def forward_client_3(encoder_output, labels):\n",
        "    # Move encoder_output to device3\n",
        "    encoder_output = encoder_output.last_hidden_state[:, 0, :].to(device3)  # [CLS] token for classification\n",
        "\n",
        "    # Process through classification head\n",
        "    logits = model.classifier(encoder_output)\n",
        "    labels = labels.to(device3)\n",
        "\n",
        "    # Logits should have shape (batch_size, num_classes)\n",
        "    #print(f\"Client 3 - Output Shape: {logits.shape}, Device: {logits.device}\")\n",
        "\n",
        "    # Ensure logits have shape (batch_size, num_classes)\n",
        "    assert logits.dim() == 2 and logits.size(1) == 2, f\"Logits shape mismatch: {logits.shape}\"\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = criterion(logits, labels)\n",
        "    # print(f\"Client 3 - Loss: {loss.item()}\")\n",
        "\n",
        "    return logits\n",
        "\n",
        "# Function to train and track metrics\n",
        "def train_model(epochs):\n",
        "    list_train_accuracies = []\n",
        "    list_val_accuracies = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        total_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        # print(len(train_dataloader))\n",
        "        i = 0\n",
        "        # for batch in train_dataloader:\n",
        "        for batch in train_dataloader:\n",
        "            i +=1\n",
        "            print(f' {i}',end=\"\")\n",
        "            # Process through Client 1 (Embeddings)\n",
        "            output_client_1 = forward_client_1(batch)\n",
        "\n",
        "\n",
        "            # Process through Client 2 (Encoder)\n",
        "            output_client_2 = forward_client_2(output_client_1, batch['attention_mask'])\n",
        "\n",
        "            # Process through Client 3 (Classification and loss calculation)\n",
        "            logits = forward_client_3(output_client_2, batch['labels'])\n",
        "\n",
        "            # Move logits and labels back to CPU for metric calculation\n",
        "            all_preds.append(logits.detach().cpu())\n",
        "            all_labels.append(batch['labels'].cpu())\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(logits, batch['labels'].to(device3))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Calculate metrics at the end of each epoch\n",
        "        all_preds = torch.cat(all_preds, dim=0)\n",
        "        all_labels = torch.cat(all_labels, dim=0)\n",
        "        # epoch_accuracy = calculate_accuracy(all_preds, all_labels)\n",
        "        # average_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        # list_accuracies.append(epoch_accuracy)\n",
        "        # print(f\"Loss: {average_loss:.4f} | Accuracy: {epoch_accuracy:.4f}\")\n",
        "        train_accuracy = calculate_accuracy(all_preds, all_labels)\n",
        "        average_train_loss = total_loss / len(train_dataloader)\n",
        "        list_train_accuracies.append(train_accuracy)\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {average_train_loss:.4f} | Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()  # Set model to evaluation mode\n",
        "        val_loss = 0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():  # No gradients needed for validation\n",
        "            for val_batch in validation_dataloader:\n",
        "                output_client_1 = forward_client_1(val_batch)\n",
        "                output_client_2 = forward_client_2(output_client_1, val_batch['attention_mask'])\n",
        "                logits = forward_client_3(output_client_2, val_batch['labels'])\n",
        "\n",
        "                # Calculate validation loss\n",
        "                loss = criterion(logits, val_batch['labels'].to(device3))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                # Collect predictions for validation accuracy\n",
        "                val_preds.append(logits.detach().cpu())\n",
        "                val_labels.append(val_batch['labels'].cpu())\n",
        "\n",
        "        # Calculate validation accuracy and average loss for the epoch\n",
        "        val_preds = torch.cat(val_preds, dim=0)\n",
        "        val_labels = torch.cat(val_labels, dim=0)\n",
        "        val_accuracy = calculate_accuracy(val_preds, val_labels)\n",
        "        average_val_loss = val_loss / len(validation_dataloader)\n",
        "        list_val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Validation Loss: {average_val_loss:.4f} | Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Set model back to training mode for next epoch\n",
        "        model.train()\n",
        "\n",
        "# Train for 30 epochs\n",
        "train_model(epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Akyge3Bq7jtA",
        "outputId": "d666b6d9-8010-4da2-cd3b-bf0b6270a52c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230Epoch 1/10 - Training Loss: 0.0644 | Training Accuracy: 0.9785\n",
            "Epoch 1/10 - Validation Loss: 0.5708 | Validation Accuracy: 0.8505\n",
            " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230Epoch 2/10 - Training Loss: 0.0396 | Training Accuracy: 0.9861\n",
            "Epoch 2/10 - Validation Loss: 0.5155 | Validation Accuracy: 0.7868\n",
            " 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-300832a1a146>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m# Train for 30 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-300832a1a146>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' {i}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Process through Client 1 (Embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0moutput_client_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_client_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-300832a1a146>\u001b[0m in \u001b[0;36mforward_client_1\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Function to process data through client 1 (embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_client_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Split the model into clients (no pooler in ALBERT)\n",
        "model.albert.embeddings.to(device1)\n",
        "model.albert.encoder.to(device2)\n",
        "model.classifier.to(device3)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "# for using accuracy score we need to pass data from GPU to cpu\n",
        "def calculate_accuracy(preds, labels):\n",
        "    # print(f'preds is {preds} and label is ${labels}')\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "    # print(f'preads:{preds}')\n",
        "    return accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "\n",
        "# def calculate_accuracy(preds, labels):\n",
        "#     preds = torch.argmax(preds, dim=1)\n",
        "#     correct = (preds == labels).sum().item()\n",
        "#     return correct / len(labels)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_XrZVo-PyWh7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get only the first batch from train_dataloader\n",
        "first_batch = next(iter(train_dataloader))\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAR1KNRu_ROC",
        "outputId": "fa075f34-3fcd-460a-b23d-3c83673b8ac2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    2,  2962, 13102,  ...,     0,     0,     0],\n",
            "        [    2,    13,     7,  ...,     0,     0,     0],\n",
            "        [    2,   236,   159,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [    2, 12885,    13,  ...,     0,     0,     0],\n",
            "        [    2,    40,  2383,  ...,     0,     0,     0],\n",
            "        [    2,    14,   234,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAwNokRAxcgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882f1370-4a2a-4d6f-b708-c4e1263e7cba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlbertForSequenceClassification(\n",
            "  (albert): AlbertModel(\n",
            "    (embeddings): AlbertEmbeddings(\n",
            "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 128)\n",
            "      (token_type_embeddings): Embedding(2, 128)\n",
            "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0, inplace=False)\n",
            "    )\n",
            "    (encoder): AlbertTransformer(\n",
            "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
            "      (albert_layer_groups): ModuleList(\n",
            "        (0): AlbertLayerGroup(\n",
            "          (albert_layers): ModuleList(\n",
            "            (0): AlbertLayer(\n",
            "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (attention): AlbertAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (attention_dropout): Dropout(p=0, inplace=False)\n",
            "                (output_dropout): Dropout(p=0, inplace=False)\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              )\n",
            "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (activation): NewGELUActivation()\n",
            "              (dropout): Dropout(p=0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (pooler_activation): Tanh()\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcEXw7HSU1Ke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}