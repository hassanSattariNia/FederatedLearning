{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **class Client**"
      ],
      "metadata": {
        "id": "ez727RVlqM_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N5W4Ek62LXGt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import threading\n",
        "import queue\n",
        "class Client:\n",
        "  def __init__(self, client_id,partition1, partition, input_queue=None, data_loader=None):\n",
        "\n",
        "        self.client_id = client_id\n",
        "        self.partition = partition\n",
        "        self.partition1 = partition1\n",
        "        self.input_queue = input_queue\n",
        "        self.data_loader = data_loader\n",
        "\n",
        "  def process_partition1(self , data ):\n",
        "    data_tensor = torch.tensor(data)\n",
        "    return self.partition1(data_tensor)\n",
        "\n",
        "\n",
        "  def process_partition(self , data ):\n",
        "    data_tensor = torch.tensor(data)\n",
        "    return self.partition(data_tensor)\n",
        "\n",
        "  # calculate loss function\n",
        "  def process_final_partition(self , data):\n",
        "    print(\"calculate loss function here\")\n",
        "\n",
        "\n",
        "  def run(self):\n",
        "    while True:\n",
        "      if self.input_queue and not self.input_queue.empty():\n",
        "        data = self.input_queue.get()\n",
        "        x = data[\"output\"]\n",
        "        stage = data[\"stage\"]\n",
        "        source = data[\"source\"]\n",
        "        destination = data[\"destination\"]\n",
        "        client_id = data[\"client_id\"]\n",
        "\n",
        "        if self.client_id ==1 and ( stage !=1 and stage != 4):\n",
        "          print(\"you shoulnt be here !!!\")\n",
        "          break\n",
        "\n",
        "        # handle stage == 1\n",
        "        if stage == 1 :\n",
        "          output = self.process_partition1(x)\n",
        "          stage +=1\n",
        "          self.input_queue[stage].put({\n",
        "               \"output\":output ,\n",
        "                \"stage\":stage,\n",
        "                \"source\":self.client_id,\n",
        "                \"destination\":stage,\n",
        "                \"client_id\":client_id\n",
        "          })\n",
        "        elif stage !=5:\n",
        "          output = self.process_partition(x)\n",
        "          print(f\"x value in client[{client_id}]stage:[{stage}]\")\n",
        "          stage +=1\n",
        "          self.input_queue[stage].put({\n",
        "                \"output\":output ,\n",
        "                \"stage\":stage,\n",
        "                \"source\":self.client_id,\n",
        "                \"destination\":stage,\n",
        "                \"client_id\":client_id\n",
        "            })\n",
        "        else:\n",
        "            print(\"final partition\")\n",
        "            self.process_final_partition(x)\n",
        "      else:\n",
        "        if self.data_loader:\n",
        "          inputs , labels = self.data_loader.get_next_batch()\n",
        "        self.input_queue[self.client_id].put({\n",
        "            \"output\":inputs ,\n",
        "            \"stage\":1,\n",
        "            \"source\":self.client_id,\n",
        "            \"destination\":self.client_id,\n",
        "            \"client_id\":self.client_id\n",
        "        })\n",
        "      time.sleep(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loader Class**"
      ],
      "metadata": {
        "id": "DXhlcehSqQ4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader as TorchDataLoader\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, dataset, batch_size=32, shuffle=True, train_ratio=0.8):\n",
        "        \"\"\"\n",
        "        Initialize the DataLoader with specific configurations.\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.train_ratio = train_ratio\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.dataset_train, self.dataset_test = self.loadDataSet()\n",
        "\n",
        "        # ایجاد DataLoader برای train و test\n",
        "        self.train_loader = TorchDataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=self.shuffle)\n",
        "        self.test_loader = TorchDataLoader(self.dataset_test, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "        self.train_iter = iter(self.train_loader)\n",
        "        self.test_iter = iter(self.test_loader)\n",
        "        self.mode = \"train\"\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"\n",
        "        Set the mode to 'train' or 'test'.\n",
        "        \"\"\"\n",
        "        if mode not in [\"train\", \"test\"]:\n",
        "            raise ValueError(\"Mode must be either 'train' or 'test'\")\n",
        "        self.mode = mode\n",
        "        # بازنشانی iterator\n",
        "        if self.mode == \"train\":\n",
        "            self.train_iter = iter(self.train_loader)\n",
        "        else:\n",
        "            self.test_iter = iter(self.test_loader)\n",
        "\n",
        "    def loadDataSet(self):\n",
        "        \"\"\"\n",
        "        Load CIFAR-10 dataset.\n",
        "        \"\"\"\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=self.transform)\n",
        "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=self.transform)\n",
        "        return trainset, testset\n",
        "\n",
        "    def getLoader(self):\n",
        "        \"\"\"\n",
        "        Return the appropriate DataLoader based on the mode.\n",
        "        \"\"\"\n",
        "        return self.train_loader if self.mode == \"train\" else self.test_loader\n",
        "\n",
        "    def get_next_batch(self):\n",
        "        \"\"\"\n",
        "        Return the next batch of data.\n",
        "        \"\"\"\n",
        "        if self.mode == \"train\":\n",
        "            try:\n",
        "                batch = next(self.train_iter)\n",
        "            except StopIteration:\n",
        "                # اگر به انتهای دیتاست رسیدیم، دوباره از ابتدا شروع کن\n",
        "                self.train_iter = iter(self.train_loader)\n",
        "                batch = next(self.train_iter)\n",
        "        else:\n",
        "            try:\n",
        "                batch = next(self.test_iter)\n",
        "            except StopIteration:\n",
        "                # اگر به انتهای دیتاست رسیدیم، دوباره از ابتدا شروع کن\n",
        "                self.test_iter = iter(self.test_loader)\n",
        "                batch = next(self.test_iter)\n",
        "\n",
        "        return batch\n"
      ],
      "metadata": {
        "id": "X7YBTKH5oEMC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **test DataLoader Class**"
      ],
      "metadata": {
        "id": "e3tkihscKSue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(dataset=None , batch_size=64)\n",
        "data_loader.set_mode(\"train\")\n",
        "\n",
        "batch_count = 0\n",
        "while True:\n",
        "  inputs , labels = data_loader.get_next_batch()\n",
        "  print(f\"fetch {batch_count} and input shape is :${labels.shape}\")\n",
        "  batch_count +=1\n",
        "\n",
        "  if batch_count ==10 :\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNkny5nR4yPR",
        "outputId": "48d07719-c92f-4422-bbec-0ad3ed5f0153"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "fetch 0 and input shape is :$torch.Size([64])\n",
            "fetch 1 and input shape is :$torch.Size([64])\n",
            "fetch 2 and input shape is :$torch.Size([64])\n",
            "fetch 3 and input shape is :$torch.Size([64])\n",
            "fetch 4 and input shape is :$torch.Size([64])\n",
            "fetch 5 and input shape is :$torch.Size([64])\n",
            "fetch 6 and input shape is :$torch.Size([64])\n",
            "fetch 7 and input shape is :$torch.Size([64])\n",
            "fetch 8 and input shape is :$torch.Size([64])\n",
            "fetch 9 and input shape is :$torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# BasicBlock\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "HPJjsUul3w-U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **define Partion class**"
      ],
      "metadata": {
        "id": "LUtNSmZ-v_E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Partition(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Partition, self).__init__()\n",
        "        self.layers = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        raise NotImplementedError(\"Subclasses should implement this method\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "7yDRNLrOLm_Z"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Partition1(Partition):\n",
        "    def build_model(self):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "class Partition2(Partition):\n",
        "    def build_model(self):\n",
        "        return nn.Sequential(\n",
        "            BasicBlock(64, 64, stride=1),\n",
        "            BasicBlock(64, 128, stride=2)\n",
        "        )\n",
        "\n",
        "class Partition3(Partition):\n",
        "    def build_model(self):\n",
        "        return nn.Sequential(\n",
        "            BasicBlock(128, 256, stride=2),\n",
        "            BasicBlock(256, 512, stride=2)\n",
        "        )\n",
        "\n",
        "class Partition4(Partition):\n",
        "    def build_model(self):\n",
        "        return nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n"
      ],
      "metadata": {
        "id": "Ta_ctSOPwRsi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test partitions and basic Block**\n"
      ],
      "metadata": {
        "id": "wZqrka4288xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "data_loader = DataLoader(dataset=None , batch_size=8)\n",
        "data_loader.set_mode(\"test\")\n",
        "\n",
        "partition1 = Partition1().to(device)\n",
        "partition2 = Partition2().to(device)\n",
        "partition3 = Partition3().to(device)\n",
        "partition4 = Partition4().to(device)\n",
        "\n",
        "\n",
        "images, labels = data_loader.get_next_batch()\n",
        "\n",
        "# عبور دادن ورودی از طریق پارتیشن‌ها\n",
        "print(\"Running Partition1...\")\n",
        "output1 = partition1(images)\n",
        "print(f\"Output shape after Partition1: {output1.shape}\")\n",
        "\n",
        "print(\"Running Partition2...\")\n",
        "output2 = partition2(output1)\n",
        "print(f\"Output shape after Partition2: {output2.shape}\")\n",
        "\n",
        "print(\"Running Partition3...\")\n",
        "output3 = partition3(output2)\n",
        "print(f\"Output shape after Partition3: {output3.shape}\")\n",
        "\n",
        "print(\"Running Partition4...\")\n",
        "output4 = partition4(output3)\n",
        "print(f\"Output shape after Partition4: {output4.shape}\")\n",
        "\n",
        "# محاسبه پیش‌بینی نهایی\n",
        "_, predicted = torch.max(output4, 1)\n",
        "print(f\"Predicted labels: {predicted}\")\n",
        "print(f\"True labels: {labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nU88fJQ9Jh_",
        "outputId": "e6d01b1a-757f-4fcb-897e-b046d0fb05e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Running Partition1...\n",
            "Output shape after Partition1: torch.Size([8, 64, 32, 32])\n",
            "Running Partition2...\n",
            "Output shape after Partition2: torch.Size([8, 128, 16, 16])\n",
            "Running Partition3...\n",
            "Output shape after Partition3: torch.Size([8, 512, 4, 4])\n",
            "Running Partition4...\n",
            "Output shape after Partition4: torch.Size([8, 10])\n",
            "Predicted labels: tensor([5, 5, 5, 5, 5, 6, 5, 5])\n",
            "True labels: tensor([3, 8, 8, 0, 6, 6, 1, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Message Class**"
      ],
      "metadata": {
        "id": "GicodSAJ-x6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Message:\n",
        "  def __init__(self , message_type , stage, source , destination,data_id,data):\n",
        "    self.message_type = message_type\n",
        "    self.stage = stage\n",
        "    self.source = source\n",
        "    self.destination = destination\n",
        "    self.data_id = data_id\n",
        "    self.data = data"
      ],
      "metadata": {
        "id": "1eF250QU8hfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **simulate logic Client Running with Thread**"
      ],
      "metadata": {
        "id": "SUHXr0H-Q0LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "import time\n",
        "import threading\n",
        "\n",
        "class Partition1:\n",
        "    def process(self, client_id):\n",
        "        print(\"partition 1\")\n",
        "        return client_id  #return client id\n",
        "\n",
        "class Partition2:\n",
        "    def process(self, x):\n",
        "        print(\"partition 2\")\n",
        "        return x + 2\n",
        "\n",
        "class Partition3:\n",
        "    def process(self, x):\n",
        "        print(\"partition 3\")\n",
        "        return x * 4\n",
        "\n",
        "class Partition4:\n",
        "    def process(self, x):\n",
        "        print(\"partition 4\")\n",
        "        return x - 1\n",
        "\n",
        "class FinalPartition:\n",
        "    def process(self, x, label):\n",
        "        print(f\"Computed Value: {x}, Expected Label: {label}\")\n",
        "        if x == label:\n",
        "            print(\"Success!\")\n",
        "        else:\n",
        "            print(\"Failed!\")\n",
        "\n",
        "\n",
        "\n",
        "# Label‌ها\n",
        "labels = {1: 11, 2: 15, 3: 19, 4: 23}\n",
        "\n",
        "class Client(threading.Thread):\n",
        "    def __init__(self, client_id, partition1, partition, final_partition  , input_queue ):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.client_id = client_id\n",
        "        self.partition1 = partition1\n",
        "        self.partition = partition\n",
        "        self.final_partition = final_partition\n",
        "        self.input_queue = input_queue\n",
        "    def run(self):\n",
        "      while True:\n",
        "          # check input list\n",
        "        if not self.input_queue[self.client_id].empty():\n",
        "          data = self.input_queue[self.client_id].get()\n",
        "          x = data[\"output\"]\n",
        "          stage = data[\"stage\"]\n",
        "          source = data[\"source\"]\n",
        "          destination = data[\"destination\"]\n",
        "          client_id = data[\"client_id\"]\n",
        "\n",
        "          if self.client_id==1 and (stage !=1 and stage !=4):\n",
        "            print(f'fuck................{stage}')\n",
        "            break\n",
        "\n",
        "          # data come from stage4\n",
        "          # if stage == 4 and client_id==self.client_id:\n",
        "          #   print(f\"final partition for client ${self.client_id}\")\n",
        "          #   self.final_partition.process(x)\n",
        "          if stage == 1:\n",
        "            x = self.partition1.process(x)\n",
        "            stage += 1\n",
        "            self.input_queue[stage].put({\n",
        "                \"output\":x ,\n",
        "                \"stage\":stage,\n",
        "                \"source\":self.client_id,\n",
        "                \"destination\":stage,\n",
        "                \"client_id\":client_id\n",
        "            })\n",
        "          elif stage!=5:\n",
        "            x = self.partition.process(x)\n",
        "            print(f\"x value in client[{client_id}]stage:[{stage}]={x}\")\n",
        "            stage +=1\n",
        "            self.input_queue[stage].put({\n",
        "                \"output\":x ,\n",
        "                \"stage\":stage,\n",
        "                \"source\":self.client_id,\n",
        "                \"destination\":stage,\n",
        "                \"client_id\":client_id\n",
        "            })\n",
        "          else:\n",
        "            print(\"final partition\")\n",
        "            self.final_partition.process(x , labels[self.client_id])\n",
        "        else:\n",
        "          self.input_queue[self.client_id].put({\n",
        "                \"output\":self.client_id ,\n",
        "                \"stage\":1,\n",
        "                \"source\":self.client_id,\n",
        "                \"destination\":self.client_id,\n",
        "                \"client_id\":self.client_id})\n",
        "\n",
        "        time.sleep(5)\n",
        "      # read from input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_queues(queues):\n",
        "    for key, q in queues.items():\n",
        "        items = list(q.queue)  # Accessing internal queue list (not thread-safe)\n",
        "        print(f\"Queue {key}: {items}\")"
      ],
      "metadata": {
        "id": "oZVR3_C-7Iy8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "\n",
        "queues = {\n",
        "    1: queue.Queue(),\n",
        "    2: queue.Queue(),\n",
        "    3: queue.Queue(),\n",
        "    4: queue.Queue(),\n",
        "    5: queue.Queue()\n",
        "}\n",
        "partition1 = Partition1()\n",
        "partition2 = Partition2()\n",
        "partition3 = Partition3()\n",
        "partition4 = Partition4()\n",
        "final_partition = FinalPartition()\n",
        "\n",
        "\n",
        "client1 = Client(1, partition1, None, final_partition, queues)\n",
        "client2 = Client(2, partition1, partition2, final_partition, queues)\n",
        "client3 = Client(3, partition1, partition3, final_partition, queues)\n",
        "client4 = Client(4, partition1, partition4, final_partition, queues)\n",
        "\n",
        "# runinng client parallel\n",
        "clients = [client1, client2, client3, client4]\n",
        "for client in clients:\n",
        "    client.start()\n",
        "\n",
        "for client in clients:\n",
        "    client.join()\n"
      ],
      "metadata": {
        "id": "mFGtwp3cGU4P",
        "outputId": "c2e1ff35-0344-47d0-cb6a-4d739d71a973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Exception in thread Thread-11:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Exception in thread Thread-10Thread-12:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "Exception in thread Thread-13:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            ":\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"<ipython-input-2-d725768aaac4>\", line 50, in run\n",
            "    self.run()\n",
            "  File \"<ipython-input-2-d725768aaac4>\", line 50, in run\n",
            "    self.run()    self.run()\n",
            "  File \"<ipython-input-2-d725768aaac4>\", line 50, in run\n",
            "\n",
            "  File \"<ipython-input-2-d725768aaac4>\", line 50, in run\n",
            "TypeError: 'Queue' object is not subscriptable\n",
            "TypeError: 'Queue' object is not subscriptable\n",
            "TypeError: 'Queue' object is not subscriptable\n",
            "TypeError: 'Queue' object is not subscriptable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "printQueue()"
      ],
      "metadata": {
        "id": "L5MTAxYLUzcL",
        "outputId": "616e5e92-da11-479f-aea1-3de1d3802ba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "\n",
        "# Sample data\n",
        "queues = {\n",
        "    1: queue.Queue(),\n",
        "    2: queue.Queue(),\n",
        "    3: queue.Queue(),\n",
        "    4: queue.Queue()\n",
        "}\n",
        "\n",
        "# Add some items to the queues\n",
        "queues[1].put(\"task1\")\n",
        "queues[2].put(\"task2\")\n",
        "queues[2].put(\"task3\")\n",
        "queues[3].put(\"task4\")\n",
        "\n",
        "# Print the contents of each queue\n",
        "\n",
        "\n",
        "print_queues(queues)\n"
      ],
      "metadata": {
        "id": "tpjdFbZOdRmH",
        "outputId": "0992fc53-e2fd-4abd-9f77-87532e1adc41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queue 1: ['task1']\n",
            "Queue 2: ['task2', 'task3']\n",
            "Queue 3: ['task4']\n",
            "Queue 4: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fsSuuDRQukbo"
      }
    }
  ]
}